import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import time
import re

# ==============================================================================
# 1. CONFIGURACI√ìN VISUAL (MODO CONSULTOR EXPERTO)
# ==============================================================================
st.set_page_config(
    page_title="Petrolito AI | Proyecciones Estrat√©gicas",
    layout="wide",
    page_icon="üß†",
    initial_sidebar_state="collapsed"
)

# Estilos CSS para inmersi√≥n total
st.markdown("""
<style>
    .block-container {
        padding-top: 2rem !important;
        padding-bottom: 5rem !important;
        max-width: 900px !important;
    }
    [data-testid="stAppViewContainer"] {
        background-color: #0F172A; /* Azul noche profundo */
    }
    
    /* BURBUJAS DE CHAT */
    .chat-bubble {
        padding: 22px;
        border-radius: 12px;
        margin-bottom: 24px;
        line-height: 1.6;
        font-family: 'Segoe UI', sans-serif;
        font-size: 15px;
        box-shadow: 0 4px 12px rgba(0,0,0,0.2);
    }
    
    .user-bubble {
        background-color: #334155;
        border: 1px solid #475569;
        color: #F8FAFC;
        margin-left: 15%;
        border-radius: 15px 15px 2px 15px;
        text-align: right;
    }
    
    .bot-bubble {
        background-color: #1E293B;
        border-left: 4px solid #00C851; /* Verde Petrolito */
        color: #CBD5E1;
        margin-right: 5%;
        border-radius: 15px 15px 15px 2px;
    }

    /* ESTILOS DE TEXTO RICOS */
    .bot-bubble h3 { color: #38BDF8 !important; margin: 0 0 12px 0; font-size: 19px; font-weight: 600; }
    .bot-bubble strong { color: #00C851; font-weight: 600; }
    .bot-bubble em { color: #94A3B8; font-style: italic; }
    
    /* SUGERENCIAS (BOTONES) */
    .suggestion-btn {
        display: inline-block;
        background: rgba(56, 189, 248, 0.1);
        border: 1px solid #38BDF8;
        color: #38BDF8;
        padding: 5px 12px;
        border-radius: 20px;
        font-size: 13px;
        margin-right: 8px;
        margin-top: 8px;
        cursor: default;
    }

    /* INPUT FLOTANTE */
    .stChatInput {
        position: fixed;
        bottom: 25px;
        left: 50%;
        transform: translateX(-50%);
        width: 800px !important;
        z-index: 9999;
    }
</style>
""", unsafe_allow_html=True)

# ==============================================================================
# 2. CEREBRO DE PETROLITO (L√ìGICA AVANZADA)
# ==============================================================================

if 'memory_state' not in st.session_state:
    st.session_state.memory_state = {
        "wti": 76.5,          # Precio barril actual
        "produccion": 95.0,   # Miles barriles/d√≠a
        "tema_anterior": None # Para entender contexto ("¬øY la deuda?")
    }

class PetrolitoBrain:
    def __init__(self):
        # Base de Datos Simulada
        self.db_files = pd.DataFrame({
            "Documento": ["Auditor√≠a Costos NRT", "Perfil Deuda Sindicada", "Proyecci√≥n Flujo Caja Q4"],
            "Fuente": ["PwC", "Gerencia Finanzas", "Petrolito AI"],
            "Fecha": ["2024-05", "2024-06", "Tiempo Real"]
        })

    # --- 1. MOTOR DE APRENDIZAJE Y CONTEXTO ---
    def analizar_input(self, prompt):
        """Detecta par√°metros, intenci√≥n y actualiza la memoria."""
        prompt_low = prompt.lower()
        state = st.session_state.memory_state
        learned_msg = ""
        intent = "general"

        # A. Actualizaci√≥n de Variables (Learning)
        # Regex flexible para captar "WTI a 80" o "Precio 80"
        match_wti = re.search(r'(wti|precio|barril).*?(\d{2,3}(\.\d+)?)', prompt_low)
        if match_wti:
            nuevo = float(match_wti.group(2))
            state['wti'] = nuevo
            learned_msg += f"üìù *He recalibrado mis modelos con un WTI de ${nuevo}.* "

        match_prod = re.search(r'(producci.n|refineria).*?(\d{2,3})', prompt_low)
        if match_prod:
            nuevo = float(match_prod.group(2))
            state['produccion'] = nuevo
            learned_msg += f"üìù *Ajust√© la carga de refiner√≠a a {nuevo} KBPD.* "

        # B. Detecci√≥n de Intenci√≥n (Fuzzy Logic)
        if any(x in prompt_low for x in ["talara", "refineria", "nrt", "costos"]):
            intent = "talara"
        elif any(x in prompt_low for x in ["deuda", "bonos", "financiero", "dinero", "caja", "ebitda", "flujo"]):
            intent = "finanzas"
        elif any(x in prompt_low for x in ["archivo", "descargar", "documento"]):
            intent = "archivos"
        # Manejo de contexto impl√≠cito ("¬øY c√≥mo afecta eso?", "¬øY la producci√≥n?")
        elif len(prompt.split()) < 4 and state['tema_anterior']:
             # Si la frase es corta, asumimos que sigue hablando del tema anterior
             intent = state['tema_anterior']
        
        # Guardar tema para la pr√≥xima (Memoria de Corto Plazo)
        state['tema_anterior'] = intent
        
        return intent, learned_msg

    # --- 2. GENERADORES DE PROYECCIONES (VISUALES) ---
    def _grafico_proyeccion(self):
        wti = st.session_state.memory_state['wti']
        prod = st.session_state.memory_state['produccion']
        
        # Modelo Matem√°tico Simplificado de Petrolito
        # EBITDA = Base + (Delta WTI * Sensibilidad) + (Delta Prod * Eficiencia)
        ebitda_base = 100 
        impacto_wti = (wti - 70) * 2.5
        impacto_prod = (prod - 95) * 1.5
        ebitda_final = ebitda_base + impacto_wti + impacto_prod

        meses = ['Hist√≥rico', 'Mes Actual', '+1 Mes', '+2 Meses', '+3 Meses (Proy)']
        # Datos simulados con tendencia
        valores = [90, 95, ebitda_final*0.9, ebitda_final*0.95, ebitda_final]
        
        colores = ['#64748B']*2 + ['#00C851']*3 # Gris para pasado, Verde para futuro

        fig = go.Figure()
        fig.add_trace(go.Bar(
            x=meses, y=valores, marker_color=colores,
            text=[f"${v:.0f}M" for v in valores], textposition='auto'
        ))
        fig.add_trace(go.Scatter(
            x=meses, y=[v*1.05 for v in valores], mode='lines', 
            name='Escenario Optimista', line=dict(color='#38BDF8', dash='dash')
        ))
        
        fig.update_layout(
            title=f"Proyecci√≥n EBITDA (Escenario: WTI ${wti})",
            template="plotly_dark", paper_bgcolor='rgba(0,0,0,0)', plot_bgcolor='rgba(0,0,0,0)',
            height=300, margin=dict(l=20, r=20, t=40, b=20),
            font=dict(family="Segoe UI")
        )
        return fig

    # --- 3. GENERADOR DE RESPUESTA HUMANIZADA ---
    def generar_respuesta(self, prompt):
        intent, learned_header = self.analizar_input(prompt)
        response = {"texto": "", "visuales": []}
        state = st.session_state.memory_state

        # INTENCI√ìN: FINANZAS / PROYECCI√ìN
        if intent == "finanzas":
            response["texto"] = (
                f"{learned_header}\n"
                f"### üìä An√°lisis de Solvencia y Proyecci√≥n\n"
                f"Analizando los fundamentales actuales (WTI **${state['wti']}**), preveo una recuperaci√≥n progresiva del flujo de caja.\n\n"
                f"Si bien la deuda estructural sigue siendo un desaf√≠o, el EBITDA proyectado muestra una tendencia positiva gracias a los precios actuales. "
                f"Aqu√≠ le presento la simulaci√≥n a 3 meses bajo las condiciones que me indic√≥:"
            )
            response["visuales"].append(("grafico", self._grafico_proyeccion()))
            
        # INTENCI√ìN: TALARA / OPERACIONES
        elif intent == "talara":
            response["texto"] = (
                f"{learned_header}\n"
                f"### üè≠ Nueva Refiner√≠a Talara (NRT)\n"
                f"Entendido. Respecto a la operaci√≥n t√©cnica, estamos procesando **{state['produccion']} mil barriles diarios**.\n\n"
                f"La unidad de Flexicoking est√° estable. Sin embargo, para maximizar el margen de refino, "
                f"recomendar√≠a vigilar el *Crack Spread* del di√©sel. T√©cnicamente, la refiner√≠a es rentable operativamente con estos vol√∫menes."
            )
            # Podr√≠amos a√±adir gr√°fico de costos aqu√≠ si fuera necesario
            
        # INTENCI√ìN: ARCHIVOS
        elif intent == "archivos":
            response["texto"] = (
                "### üìÇ Data Room Corporativo\n"
                "He recuperado los documentos oficiales m√°s recientes desde el servidor seguro. "
                "Puede descargarlos o visualizarlos directamente:"
            )
            response["visuales"].append(("tabla", self.db_files))

        # INTENCI√ìN: AMBIGUA / GENERAL (GU√çA PROACTIVA)
        else:
            response["texto"] = (
                f"{learned_header}\n"
                f"### ü§ñ Estoy listo, colega.\n"
                f"Actualmente mis proyecciones corren con un **WTI de ${state['wti']}** y una producci√≥n de **{state['produccion']}k**.\n\n"
                f"Si la consulta es vaga, puedo sugerirle profundizar en:\n"
                f"<span class='suggestion-btn'>üìà Proyectar Flujo de Caja</span> "
                f"<span class='suggestion-btn'>üè≠ Ver Estado Talara</span> "
                f"<span class='suggestion-btn'>üìâ Analizar Deuda</span>\n\n"
                f"*¬øSobre qu√© eje estrat√©gico desea que profundice?*"
            )

        return response

brain = PetrolitoBrain()

# ==============================================================================
# 3. GESTI√ìN DEL CHAT
# ==============================================================================

if "mensajes" not in st.session_state:
    st.session_state.mensajes = []
    # Saludo inicial emp√°tico
    st.session_state.mensajes.append({
        "role": "assistant", 
        "contenido": {
            "texto": (
                "üëã **Hola, soy Petrolito.**\n\n"
                "Estoy conectado a los datos de mercado en tiempo real (simulado). "
                "Puedo hacer proyecciones financieras, analizar Talara o recalibrar mis modelos si t√∫ me das nuevos datos.\n\n"
                "*Prueba dici√©ndome: 'El WTI subi√≥ a 85' o simplemente preg√∫ntame '¬øC√≥mo est√° la refiner√≠a?'*"
            ),
            "visuales": []
        }
    })

# ==============================================================================
# 4. RENDERIZADO DEL CHAT
# ==============================================================================

# Header limpio
st.markdown("<h2 style='text-align:center; color:#E2E8F0;'>ü§ñ Petrolito <span style='color:#00C851;'>AI</span></h2>", unsafe_allow_html=True)

# Render Loop
for msg in st.session_state.mensajes:
    if msg["role"] == "user":
        st.markdown(f"""<div class="chat-bubble user-bubble">{msg["contenido"]}</div>""", unsafe_allow_html=True)
    else:
        pkg = msg["contenido"]
        # Render Bot
        st.markdown(f"""
        <div class="chat-bubble bot-bubble">
            <div style="display:flex; align-items:center; margin-bottom:10px;">
                <span style="font-size:22px; margin-right:10px;">ü§ñ</span>
                <span style="font-weight:bold; color:#00C851; font-size:16px;">PETROLITO</span>
            </div>
            {pkg['texto']}
        </div>
        """, unsafe_allow_html=True)
        
        # Render Visuales Interactivos
        if pkg["visuales"]:
            with st.container():
                for tipo, data in pkg["visuales"]:
                    if tipo == "grafico":
                        st.plotly_chart(data, use_container_width=True)
                    elif tipo == "tabla":
                        st.dataframe(data, use_container_width=True, hide_index=True)

# ==============================================================================
# 5. INPUT Y PROCESAMIENTO
# ==============================================================================

if prompt := st.chat_input("Consulta a Petrolito (Ej: 'Proyecta el EBITDA' o 'El WTI baj√≥ a 70')"):
    # 1. Guardar mensaje usuario
    st.session_state.mensajes.append({"role": "user", "contenido": prompt})
    st.rerun()

# Respuesta Inmediata
if st.session_state.mensajes and st.session_state.mensajes[-1]["role"] == "user":
    with st.spinner("Petrolito est√° analizando escenarios..."):
        time.sleep(0.6) # Peque√±a latencia para naturalidad
        
        ultima_entrada = st.session_state.mensajes[-1]["contenido"]
        
        # EL CEREBRO PROCESA LA RESPUESTA
        respuesta_ia = brain.generar_respuesta(ultima_entrada)
        
        st.session_state.mensajes.append({"role": "assistant", "contenido": respuesta_ia})
        st.rerun()
